
In the "correlated sampling" problem, two players, say Alice and Bob, are
given two distributions, say $P$ and $Q$ respectively, over the same universe
and access to shared randomness. The two players are required to output two
elements, without any interaction, sampled according to their respective
distributions, while trying to minimize the probability that their outputs
disagree. A well-known protocol due to Holenstein, with close variants (for
similar problems) due to Broder, and to Kleinberg and Tardos, solves this task
with disagreement probability at most $2 \delta/(1+\delta)$, where $\delta$ is
the total variation distance between $P$ and $Q$. This protocol has been used
in several different contexts including sketching algorithms, approximation
algorithms based on rounding linear programming relaxations, the study of
parallel repetition and cryptography.
In this note, we give a surprisingly simple proof that this protocol is in
fact tight. Specifically, for every $\delta \in (0,1)$, we show that any
correlated sampling scheme should have disagreement probability at least
$2\delta/(1+\delta)$. This partially answers a recent question of Rivest.
Our proof is based on studying a new problem we call "constrained agreement".
Here, Alice is given a subset $A \subseteq [n]$ and is required to output an
element $i \in A$, Bob is given a subset $B \subseteq [n]$ and is required to
output an element $j \in B$, and the goal is to minimize the probability that
$i \neq j$. We prove tight bounds on this question, which turn out to imply
tight bounds for correlated sampling. Though we settle basic questions about
the two problems, our formulation also leads to several questions that remain
open.
