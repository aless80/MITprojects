
Deep convolutional neural networks (ConvNets) of 3-dimensional kernels allow
joint modeling of spatiotemporal features. These networks have improved
performance of video and volumetric image analysis, but have been limited in
size due to the low memory ceiling of GPU hardware. Existing CPU
implementations overcome this constraint but are impractically slow. Here we
extend and optimize the faster Winograd-class of convolutional algorithms to
the $N$-dimensional case and specifically for CPU hardware. First, we remove
the need to manually hand-craft algorithms by exploiting the relaxed
constraints and cheap sparse access of CPU memory. Second, we maximize CPU
utilization and multicore scalability by transforming data matrices to be
cache-aware, integer multiples of AVX vector widths. Treating 2-dimensional
ConvNets as a special (and the least beneficial) case of our approach, we
demonstrate a 5 to 25-fold improvement in throughput compared to previous
state-of-the-art.
