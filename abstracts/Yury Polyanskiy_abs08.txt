
A channel coding achievability bound expressed in terms of the ratio between
two Neyman-Pearson $\beta$ functions is proposed. This bound is the dual of a
converse bound established earlier by Polyanskiy and Verd\'{u} (2014). The new
bound turns out to simplify considerably the analysis in situations where the
channel output distribution is not a product distribution, for example due to a
cost constraint or a structural constraint (such as orthogonality or constant
composition) on the channel inputs. Connections to existing bounds in the
literature are discussed. The bound is then used to derive 1) an achievability
bound on the channel dispersion of additive non-Gaussian noise channels with
random Gaussian codebooks, 2) the channel dispersion of the exponential-noise
channel, 3) a second-order expansion for the minimum energy per bit of an AWGN
channel, and 4) a lower bound on the maximum coding rate of a multiple-input
multiple-output Rayleigh-fading channel with perfect channel state information
at the receiver, which is the tightest known achievability result.
